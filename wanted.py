# ì›í‹°ë“œ í™ˆë¶€í„° ì‹œì‘
# playwrightë¡œ ê²€ìƒ‰ > í¬ì§€ì…˜ > 3ì´ˆ ë©ˆì¶¤ > ìŠ¤í¬ë¡¤ 3ë²ˆ ë‚´ë¦° ë’¤ > ì¹´ë“œ ê¸ì–´ì˜¤ê¸°

from playwright.sync_api import sync_playwright
import time
from bs4 import BeautifulSoup
import csv

URL = "https://www.wanted.co.kr"

# ì›í‹°ë“œ ì±„ìš© ì •ë³´ ìŠ¤í¬ë˜í•‘
def scrape_wanted(keyword):
  print(f"ğŸ” Scraping wanted.co.kr for {keyword}...")
  
  jobs = []

  with sync_playwright() as p:
    # ë¸Œë¼ìš°ì € ì„¤ì •
    browser = p.chromium.launch(headless=True)
    context = browser.new_context(
      user_agent=(
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
      )
    )

    page = context.new_page()
    page.goto(URL)

    # ê´‘ê³  ë‹«ê¸°
    try:
      page.wait_for_selector('iframe[title="WANTED"]', timeout=5000)
      page.frame_locator('iframe[title="WANTED"]').locator('div.close').click()
    except:
      pass

    # ê²€ìƒ‰ì°½ ëŒ€ê¸°
    page.wait_for_selector('button[aria-label="ê²€ìƒ‰"]')

    # ê²€ìƒ‰ì–´ ì…ë ¥
    page.locator('button[aria-label="ê²€ìƒ‰"]').click()
    page.get_by_placeholder("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.").fill(keyword)
    page.keyboard.press("Enter")


    # í¬ì§€ì…˜ í˜ì´ì§€ ëŒ€ê¸°
    time.sleep(3)
    page.click('a#search_tab_position')
    time.sleep(3)

    # ìŠ¤í¬ë¡¤ 3ë²ˆ ë‚´ë¦¬ê¸°
    for _ in range(3):
      # page.mouse.wheel(0, 300)
      page.keyboard.press("End")
      time.sleep(2)


    # ì¹´ë“œ ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
    content = page.content()
    soup = BeautifulSoup(content, "html.parser")
    cards = soup.find_all("a", {"data-position-list-type": "card"})

    for card in cards:
      link = f"{URL}{card['href']}"
      company = card["data-company-name"]

      title_element = card.find('strong')
      title = title_element.text if title_element else None

      reward_element = card.find('span', class_="JobCard_reward__oCSIQ")
      reward = reward_element.text if reward_element else None

      jobs.append({
        "title": title,
        "company": company,
        "link": link,
        "reward": reward
      })

    browser.close()
  
  return jobs

# CSVë¡œ ì €ì¥
def save_to_csv(datas, filename):
  file = open(f"scraped_datas/{filename}.csv", "w", encoding="utf-8")
  writer = csv.writer(file)
  writer.writerow(datas[0].keys())

  for item in datas:
    writer.writerow(item.values())

# í‚¤ì›Œë“œë¡œ ìŠ¤í¬ë˜í•‘ ë ˆì¸ ê³ 
keywords = ["íŒŒì´ì¬", "ìë°”ìŠ¤í¬ë¦½íŠ¸", "ë°ì´í„° ë¶„ì„"]

for keyword in keywords:
  datas = scrape_wanted(keyword)
  save_to_csv(datas, f"wanted_{keyword}_jobs")
